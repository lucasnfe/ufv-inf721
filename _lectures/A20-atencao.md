---
type: lecture
date: 2023-10-25T14:00
index: 20
title: Mecanismos de Atenção
tldr: "Melhorando o desemepenho de modelos sequence-to-sequence com mecanismos de atenção."
# thumbnail: /static_files/presentations/lec.jpg
links: 
    - url: /static_files/slides/A20-atencao.pdf
      name: slides
    - url: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/032d653a4f5a9c1ec32b9fc7c989ffe1/seq2seq_translation_tutorial.ipynb
      name: código    
    - url: https://youtu.be/lZ4V3k4Zs4k
      name: vídeo 1
    - url: https://youtu.be/CKGwoqNQ3qs
      name: vídeo 2
hide_from_announcments: false
---
**Leituras Sugeridas:**
- The Science of Deep Learning, Cap. 6: Sequence Models, Pags. 117-120
- Artificial Intelligence: A Modern Approach, Cap 24: Deep Learning For Natural Language Processing, Pags. 848-868 